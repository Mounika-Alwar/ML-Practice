# ML-Practice
## Machine Learning Notebooks Collection

This repository contains **10 hands-on Machine Learning notebooks** covering regression, classification, ensembles, dimensionality reduction, clustering, and anomaly detection. Each notebook includes **code, visualizations, and comparative analysis**.

---

## Notebooks Overview

1. **Linear Regression**  
   - Implement Linear Regression from scratch using NumPy.  
   - Compare with `sklearn.linear_model.LinearRegression`.  

2. **Polynomial Regression**  
   - Generate nonlinear data.  
   - Fit Linear vs Polynomial Regression using `PolynomialFeatures`.  
   - Plot underfitting vs overfitting.  

3. **Gradient Descent**  
   - Implement Batch, Stochastic, and Mini-batch Gradient Descent.  
   - Compare convergence speed and final error.  

4. **Logistic Regression**  
   - Train on a binary dataset (Titanic or Breast Cancer).  
   - Plot decision boundary.  
   - Evaluate precision, recall, and F1-score.  

5. **SVMs**  
   - Train SVM on `make_moons`.  
   - Compare linear vs RBF kernels.  
   - Tune `C` and `gamma` and visualize decision boundaries.  

6. **Decision Trees**  
   - Train on the Iris dataset.  
   - Visualize tree structure.  
   - Show effect of `max_depth` on bias vs variance.  

7. **Random Forest & Gradient Boosting**  
   - Train both models on the same dataset.  
   - Compare accuracy, feature importance, and training time.  

8. **PCA (Dimensionality Reduction)**  
   - Apply PCA on Digits/MNIST dataset.  
   - Plot cumulative explained variance.  
   - Train classifier before vs after PCA and compare accuracy.  

9. **Clustering**  
   - Apply K-Means on synthetic data.  
   - Use Elbow Method and Silhouette Score to choose `k`.  
   - Compare with Gaussian Mixture Model.  

10. **Anomaly Detection**  
    - Detect anomalies using Isolation Forest or One-Class SVM.  
    - Visualize decision function vs normal data.  

